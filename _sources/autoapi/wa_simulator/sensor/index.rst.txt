:mod:`wa_simulator.sensor`
==========================

.. py:module:: wa_simulator.sensor

.. Module Contents
.. ---------------


.. raw:: html

   <h2>Classes</h2>

.. autoapisummary::
  :nosignatures:

  wa_simulator.sensor.WASensorManager
  wa_simulator.sensor.WANoiseModel
  wa_simulator.sensor.WANoNoiseModel
  wa_simulator.sensor.WANormalDriftNoiseModel
  wa_simulator.sensor.WANormalNoiseModel
  wa_simulator.sensor.WASensor
  wa_simulator.sensor.WAIMUSensor
  wa_simulator.sensor.WAGPSSensor
  wa_simulator.sensor.WAWheelEncoderSensor

.. py:class:: WASensorManager(system: WASystem, filename: str = None)

   Bases: :class:`wa_simulator.base.WABase`

   Base class that manages sensors.

   :Parameters: * **system** (*WASystem*) -- The system for the simulation
                * **filename** (*str, optional*) -- A json file to load a scene from. Defaults to None (does nothing).

   .. method:: add_sensor(self, sensor: WASensor)

      Add a sensor to the sensor manager


   .. method:: synchronize(self, time)

      Synchronize each sensor at the specified time

      :Parameters: **time** (*float*) -- the time at which the sensors are synchronized to


   .. method:: advance(self, step)

      Advance the state of each sensor by the specified time step

      :Parameters: **step** (*float*) -- the step to update the sensor by


   .. method:: is_ok(self) -> bool

      Check whether this component is still alive.

      Depending the type of component, a specific element may "fail". For example, when
      a visualization is used that presents a GUI/window, if the user closes that display,
      this would be considered a component death. Therefore, :meth:`~is_ok` should then return
      False.

      :returns: *bool* -- True if still alive, false otherwise



.. py:class:: WANoiseModel

   Bases: :class:`abc.ABC`

   Base class for a noise model

   Very similar to ChNoiseModel (https://github.com/projectchrono/chrono/blob/feature/sensor/src/chrono_sensor/ChNoiseModel.h)
   Made because ChSensor currently _requires_ OptiX (NVIDIA proprietary software)

   .. method:: add_noise(self, data: list)
      :abstractmethod:

      Add noise to the data

      :Parameters: **data** (*list*) -- The data to add noise to



.. py:class:: WANoNoiseModel

   Bases: :class:`wa_simulator.sensor.WANoiseModel`

   Derived noise model. Does nothing

   .. method:: add_noise(self, data: list)

      Do nothing



.. py:class:: WANormalDriftNoiseModel(p: dict)

   Bases: :class:`wa_simulator.sensor.WANoiseModel`

   Derived noise model. Gaussian drifting noise with noncorrelated equal distributions

   Very similar to ChNormalDriftModel (https://github.com/projectchrono/chrono/blob/feature/sensor/src/chrono_sensor/ChNoiseModel.h)
   Made because ChSensor currently _requires_ OptiX (NVIDIA proprietary software)

   :Parameters: **p** (*dict*) -- Model properties/parameters taken from a json specification file

   .. method:: add_noise(self, data: list)

      Add noise to the data

      :Parameters: **data** (*list*) -- The data to add noise to



.. py:class:: WANormalNoiseModel(p: dict)

   Bases: :class:`wa_simulator.sensor.WANoiseModel`

   Derived noise model. Gaussian drifting noise with noncorrelated equal distributions

   Very similar to ChNormalModel (https://github.com/projectchrono/chrono/blob/feature/sensor/src/chrono_sensor/ChNoiseModel.h)
   Made because ChSensor currently _requires_ OptiX (NVIDIA proprietary software)

   :Parameters: **p** (*dict*) -- Model properties/parameters taken from a json specification file

   .. method:: add_noise(self, data: list)

      Add noise to the data

      :Parameters: **data** (*list*) -- The data to add noise to



.. py:class:: WASensor(vehicle: WAVehicle, body: WABody)

   Bases: :class:`wa_simulator.base.WABase`

   Base class for a sensor

   For the WASimulator, a sensor is a component that produces some sensor data. Each sensor is managed by a :class:`~WASensorManager`
   and will typically provide information for a vehicle or the surroundings. Common sensors used in autonomous vehicle
   applications: GPS, IMU, Camera, LiDAR.

   Sensor implementations are some what limited to the underlying backend for the simulation. If Chrono is used,
   Physics Based Rendering (PBR) sensors are available through the ray tracing engine `OptiX <https://developer.nvidia.com/optix>`_
   and `Chrono::Sensor <https://api.projectchrono.org/group__sensor__sensors.html>`_.

   :Parameters: * **vehicle** (*WAVehicle*) -- The vehicle to attach to. If not passed, body must be passed.
                * **body** (*WABody*) -- The body to attach to. If not passed, vehicle must be passed.

   .. method:: synchronize(self, time: float)
      :abstractmethod:

      Update the state of this component at the current time.

      The primary reason to decouple the update method into two separate calls (i.e. :meth:`~synchronize` and :meth:`~advance`)
      is to provide flexibility to the user and is essentially semantic. In most simple cases, a user will only need one of the two.
      Furthermore, can only use :meth:`~advance` if they prefer and just update their own :code:`time` variable. Given the unknown use cases
      for the simulator at the time of writing, it was chosen to provide two different methods with similar functionality as to allow
      the user to choose their desired implementation, rather than the writers of this package.

      As opposed to :meth:`~advance`, this method gets the current time of the simulation. As menthioned earlier,
      :meth:`~advance` and a user defined `time` variable could be used to instead to hold the current state of the simulation. However,
      to aid in generality of the package, this method is provided to simply provide the current time of the simulation to the user in a decoupled
      manner from the :meth:`~advance` method.

      :Parameters: **time** (*float*) -- The current time to synchronize to


   .. method:: advance(self, step: float)
      :abstractmethod:

      Advance the state of this component by the specified time step.

      The primary reason to decouple the update method into two separate calls (i.e. :meth:`~synchronize` and :meth:`~advance`)
      is to provide flexibility to the user and is essentially semantic. In most simple cases, a user will only need one of the two.
      Furthermore, can only use :meth:`~advance` if they prefer and just update their own :code:`time` variable. Given the unknown use cases
      for the simulator at the time of writing, it was chosen to provide two different methods with similar functionality as to allow
      the user to choose their desired implementation, rather than the writers of this package.

      :Parameters: **step** (*float*) -- The step size to advance this component by


   .. method:: is_ok(self) -> bool

      Check whether this component is still alive.

      Depending the type of component, a specific element may "fail". For example, when
      a visualization is used that presents a GUI/window, if the user closes that display,
      this would be considered a component death. Therefore, :meth:`~is_ok` should then return
      False.

      :returns: *bool* -- True if still alive, false otherwise


   .. method:: get_data(self)
      :abstractmethod:

      Get the sensor data

      Return types may vary. See the respective sensor for specifics.



.. py:class:: WAIMUSensor(system: WASystem, filename: str, vehicle: WAVehicle = None, body: WABody = None)

   Bases: :class:`wa_simulator.sensor.WASensor`

   Derived sensor class that implements an IMU model

   IMU stands for Inertial Measurement Unit. They come in all shapes and sizes. Typically, an IMU is used to
   measure position and orientation of whatever it is attached to. To do this, it is actually made up of more sensors,
   which when combined, produce a localizable reading. Common sub-sensors include Gyroscopes, Accelerometers, Altimeters and
   Magnetometer.

   This implementation combines three sensors to produce the expected output: Gyroscope, Accelerometer and Magnetometer. A good
   description of the underyling implementation can be found in `these slides <https://stanford.edu/class/ee267/lectures/lecture9.pdf>`_.

   :Parameters: * **system** (*WASystem*) -- The system for the simulation
                * **filename** (*str*) -- a json specification file that describes an IMU sensor model
                * **vehicle** (*WAVehicle, optional*) -- The vehicle to attach to. If not passed, body must be passed.
                * **body** (*WABody, optional*) -- The body to attach to. If not passed, vehicle must be passed.

   .. method:: synchronize(self, time)

      Synchronize the sensor at the specified time

      :Parameters: **time** (*float*) -- the time at which the sensors are synchronized to


   .. method:: advance(self, step)

      Advance the state of the sensor by the specified time step

      :Parameters: **step** (*float*) -- the step to update the sensor by


   .. method:: get_data(self)

      Get the sensor data

      :returns: *(WAVector, WAQuaternion, WAQuaternion)* -- Tuple in the form of (acceleration, angular_velocity, orientation)



.. py:class:: WAGPSSensor(system: WASystem, filename: str, vehicle: WAVehicle = None, body: WABody = None)

   Bases: :class:`wa_simulator.sensor.WASensor`

   Derived sensor class that implements a GPS model

   GPS stands for Global Positioning System. GPS's are everyday sensors you can find in your computer, watch, phone, etc.
   They essentially ping satilites orbiting earth for positional information. This information, in real life, is not very
   precise. IMU's and GPS's are commonly "fused" together to achieve highly accurate and reliable position information.

   :Parameters: * **system** (*WASystem*) -- The system for the simulation
                * **filename** (*str*) -- a json specification file that describes a GPS sensor model
                * **vehicle** (*WAVehicle, optional*) -- The vehicle to attach to. If not passed, body must be passed.
                * **body** (*WABody, optional*) -- The body to attach to. If not passed, vehicle must be passed.

   .. method:: synchronize(self, time)

      Synchronize the sensor at the specified time

      :Parameters: **time** (*float*) -- the time at which the sensors are synchronized to


   .. method:: advance(self, step)

      Advance the state of the sensor by the specified time step

      :Parameters: **step** (*float*) -- the step to update the sensor by


   .. method:: get_data(self) -> WAVector

      Get the sensor data

      :returns: *WAVector* -- The coordinate location of the vehicle in the form of [longitude, latitude, altitude]


   .. method:: cartesian_to_gps(coords: WAVector, ref: WAVector)
      :staticmethod:

      Convert a point from cartesian to gps

      :Parameters: * **coords** (*WAVector*) -- The coordinate to convert
                   * **ref** (*WAVector*) -- The "origin" or reference point

      :returns: *WAVector* -- The coordinate in the form of[longitude, latitude, altitude]


   .. method:: gps_to_cartesian(coords: WAVector, ref: WAVector)
      :staticmethod:

      Convert a gps coordinate to cartesian given some reference

      :Parameters: * **coords** (*WAVector*) -- The coordinate to convert
                   * **ref** (*WAVector*) -- The "origin" or reference point

      :returns: *WAVector* -- The x, y, z point in cartesian



.. py:class:: WAWheelEncoderSensor(system: WASystem, filename: str, vehicle: WAVehicle = None, body: WABody = None)

   Bases: :class:`wa_simulator.sensor.WASensor`

   Derived sensor class that implements an wheel encoder model

   Wheel encoders are common sensors used by robots to measure the rotational speed of rotational objects. For the application
   of autonomous vehicles, wheel encoders can be placed on the front or rear axles to measure the angular rotation speed of the wheels.
   Further, a wheel encoder can be placed on the steering column, to again, measure the angular speed. With the angular speed, one can
   simply integrate to find the angular position (i.e. steering angle).

   :Parameters: * **system** (*WASystem*) -- The system for the simulation
                * **filename** (*str*) -- a json specification file that describes a wheel encoder sensor model
                * **vehicle** (*WAVehicle, optional*) -- The vehicle to attach to. If not passed, body must be passed.
                * **body** (*WABody, optional*) -- The body to attach to. If not passed, vehicle must be passed.

   .. method:: synchronize(self, time)

      Synchronize the sensor at the specified time

      :Parameters: **time** (*float*) -- the time at which the sensors are synchronized to


   .. method:: advance(self, step)

      Advance the state of the sensor by the specified time step

      :Parameters: **step** (*float*) -- the step to update the sensor by


   .. method:: get_data(self)

      Get the sensor data

      :returns: *WAVector* -- The coordinate location of the vehicle in the form of [longitude, latitude, altitude]






.. raw:: html

   <h2>Methods</h2>

.. autoapisummary::
  :nosignatures:

   wa_simulator.sensor.load_sensor_suite_from_json
   wa_simulator.sensor.load_sensor_from_json

.. function:: load_sensor_suite_from_json(manager: WASensorManager, filename: str)

   Load a sensor suite from json

   Each loaded sensor will be added to the manager

   :Parameters: * **manager** (*WASensorManager*) -- The sensor manager to store all created objects in
                * **filename** (*str*) -- The json specification file that describes the sensor suite


.. function:: load_sensor_from_json(system: WASystem, filename: str, **kwargs) -> 'WASensor'

   Load a sensor from json

   :Parameters: * **system** (*WASystem*) -- The system for the simulation
                * **filename** (*str*) -- The json specification file that describes the sensor
                * **kwargs** -- Keyworded arguments. Must contain a 'vehicle' or 'body', not both.

   :returns: *WASensor* -- The created sensor





.. .. .. autoapi-nested-parse::
..
..    Wisconsin Autonomous - https://wa.wisc.edu

   Copyright (c) 2021 wa.wisc.edu
   All rights reserved.

   Use of this source code is governed by a BSD-style license that can be found
   in the LICENSE file at the top level of the repo

..
.. 